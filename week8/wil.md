# Chapter 5. Transaction Processing and Recovery
지금까지 데이터베이스 시스템의 개념을 하위 구조부터 설명했고,<br>
이제 버퍼 관리, 락 관리, 복구 같은 상위 컴포넌트를 설명.<br>

트랜잭션은 데이터베이스 관리 시스템에서 하나의 논리적 단위로 여러 작업을 묶어 처리하는 불가분의 작업 단위.<br>
트랜잭션이 실행하는 작업에는 데이터베이스 레코드의 읽기와 쓰기가 포함.<br>
트랜잭션은 반드시 ACID를 보장해야 함.<br>

- 원자성(Atomicity)<br>
    트랜잭션의 모든 단계가 성공하거나, 아니면 전혀 적용되지 않아야 함<br>
    트랜잭션은 커밋되면 모든 변경이 반영되고, 어보트되면 모든 변경이 롤백됨
- 일관성(Consistency)<br>
    트랜잭션은 데이터베이스를 한 유효 상태에서 다른 유효 상태로만 변경해야 함<br>
    모든 무결성 제약조건, 참조 무결성 등이 유지되어야 함
- 고립성(Isolation)<br>
    여러 트랜잭션들이 서로 간섭 없이 독립적으로 동작해야 함<br>
    성능상 이유로 대부분의 데이터베이스는 완전한 고립성보다 약한 수준의 고립성을 사용함
- 지속성(Durability)<br>
    트랜잭션이 커밋된 후에는 모든 변경사항이 디스크에 영구적으로 저장되어야 함<br>
    전원 장애, 시스템 장애, 크래시에도 데이터가 살아남아야 함
#### 트랜잭션 구현을 위해 필요한 컴포넌트
- 트랜잭션 관리자<br>
    노드 내에서 트랜잭션을 조정, 스케줄링, 추적.
- 락 관리자<br>
    자원 접근을 제어하고 데이터 무결성을 보장.<br>
    락 요청이 들어오면, 이미 다른 트랜잭션이 해당 락을 점유 중인지 확인함.<br>
    충돌이 없으면 락을 허가하고, 충돌이 있으면 대기 또는 어보트 후 재시도함.<br>
    락이 해제되면 대기 중인 트랜잭션 중 하나가 락을 획득함.
- 페이지 캐시<br>
    디스크와 스토리지 엔진 사이의 중간 계층임.<br>
    변경사항을 메모리에 저장하고, 아직 디스크에 동기화되지 않은 페이지를 캐시.
- 로그 관리자<br>
    캐시된 페이지에 적용된 작업의 히스토리(로그 엔트리)를 보관.<br>
    크래시 시 작업을 재적용하거나, 어보트된 트랜잭션의 변경을 되돌리는 데 사용.
## Buffer Management
대부분의 데이터베이스는 disk(slow)와 RAM(fast)로 구성된 2단계 메모리 계층 구조임.<br>
느린 디스크 접근 횟수를 줄이기 위해 페이지를 메모리에 캐싱하므로,<br>
스토리지 계층에서 페이지를 다시 요청하면, 다른 프로세스에 의해 수정되지 않았다는 전제 하에 캐시된 복사본을 반환.<br>
이 방식을 virtual disk, page cache, buffer pool이라고 부름.<br>
가상 디스크에서 읽기는, 메모리에 해당 페이지 복사본이 없을 때만 실제 디스크에 접근.<br>
페이지 캐시는 디스크에서 읽은 페이지를 메모리에 저장하고, 필요 시 반환함.<br>
데이터베이스 시스템이 크래시되거나 비정상 종료되면, 캐시에 있던 데이터는 모두 사라짐.<br>
이 책에서는 page cache라는 용어를 기본으로 사용함.<br>
buffer pool은 비어 있는 버퍼를 재사용하는 용도로도 사용되지만, page cache의 전체 목적을 정확히 반영하지는 못함.<br>

페이지 캐싱 문제는 운영체제에서도 활용.<br>
사용하지 않는 메모리 영역을 활용해 디스크 내용을 투명하게 캐시함으로써 IO 성능을 높임.<br>
메모리에 없는 페이지를 디스크에서 읽어올 때 **paged in**이라고 부름.<br>
캐시된 페이지가 수정되면 **dirty**라고 부르고, 디스크에 플러시될 때까지 dirty 상태로 남아있음.<br>
메모리에 할당된 페이지 캐시 영역은 전체 데이터셋보다 작으므로, 캐시가 가득 차면 새 페이지를 위해 기존 페이지를 evict.<br>

B-Tree 페이지의 캐시는 디스크 저장 순서와는 별개로, 빈 슬롯에 페이지를 임의 순서로 적재함.<br>

### Caching Semantics

버퍼에 생긴 변경사항들은 메모리에 있다가 디스크에 write됨.<br>
변경사항은 메모리 -> 디스크의 흐름으로 가는데 이는 단방향으로만 작동.<br>

페이지 캐시 덕에 데이터베이스는 메모리 관리와 디스크 접근을 더 잘 할 수 있음.<br>
트리의 일부분을 메모리에 유지할 수 있고 디스크 접근을 페이지 캐시 호출로 대체할 수 있음.<br>

스토리지 엔진이 페이지를 요청하면, 먼저 해당 내용이 이미 캐시에 있는지 확인함.<br>
이미 캐시되어 있으면, 캐시된 페이지 내용을 반환함.<br>
아직 캐시되어 있지 않으면, 논리적 페이지 주소나 번호를 물리적 주소로 변환해 내용을 메모리에 적재하고, 캐시된 버전을 반환함.<br>
반환된 버퍼는 참조(referenced) 상태가 됨.<br>
스토리지 엔진이 사용을 마치면, 페이지 캐시에 반환하거나 참조 해제함.<br>
페이지 캐시는 pinning을 통해 특정 페이지가 evict 되지 않도록 할 수 있음.<br>

페이지가 수정되면 dirty로 표시되고 이는 디스크와 불일치 상태임을 의미하며, durability를 위해 반드시 flush해야 함.<br>

### Cache Eviction
캐시를 가득 채워두면 디스크 접근 없이 더 많은 읽기를 처리할 수 있지만,<br>
페이지 캐시는 용량이 한정되어 있으므로, 새로운 내용을 저장하려면 기존 페이지를 evict해야 함.<br>
페이지 내용이 디스크에 이미 플러시됐거나 수정된 적이 없는 경우, 해당 페이지가 pin 혹은 reference 중이 아니라면 바로 evict 가능.<br>

반면에 dirty 페이지는 퇴출 전에 반드시 flush해야 함.<br>

다른 스레드가 사용 중인 참조된 페이지는 퇴출하면 안 됨.<br>

모든 evict마다 플러시를 트리거하면 성능이 나빠질 수 있으므로, 일부 데이터베이스는 백그라운드에서 dirty 페이지를 미리 플러시하는 프로세스를 두는데 PostgreSQL의 background flush writer가 이런 역할을 함.<br>

또 하나 중요한 특성은 내구성(durability)임.<br>
데이터베이스가 크래시되면 아직 플러시되지 않은 데이터는 모두 손실됨.<br>
모든 변경사항을 영구 저장하려면 checkpoint 프로세스가 플러시를 조정함.<br>
checkpoint는 write-ahead log와 페이지 캐시를 동기화.<br>

WAL에서 제거하려면 해당 로그가 적용된 페이지가 flush 된 상태여야 함.<br>
dirty 페이지는 이 과정이 끝나기 전까지 퇴출할 수 없음.<br>

#### trade-off
- 플러시를 미뤄 디스크 접근 횟수를 줄임.<br>
- 빠른 퇴출을 위해 preemptively 플러시함.<br>
- 퇴출할 페이지와 플러시 순서를 최적화함.<br>
- 캐시 크기를 메모리 한도 내로 유지함.<br>
- 데이터가 영구 저장되기 전에 손실되는 것을 방지함.<br>

### Locking Pages in Cache
디스크 IO를 읽기/쓰기마다 수행하는 것은 비효율적임.<br>
같은 페이지를 반복해서 읽거나, 여러 번 수정하는 경우가 많음.<br>
B-트리는 위로 갈수록(루트에 가까울수록) 노드가 적어지고, 상위 노드는 대부분의 읽기 작업에서 반복적으로 접근됨.<br>
즉, 상위 노드는 트리 전체에서 차지하는 비율이 작으므로, 이 부분을 메모리에 항상 상주시키는 것이 효과적임.<br>
이런 방법을 pin이라고 부름.<br>

분할이나 병합을 할 때도 그 작업의 영향이 상위 노드로 전파되는데,<br>
이때 상위 노드들이 캐싱되어 있다면 성능면에서 이점이 있음.<br>
결론적으로 pinning이라는건 자주 접근하는 것을 접근하기 쉬운 메모리에 상주시켜서 성능 상 이점을 보겠다는 것.<br>

pinning으로 인해 디스크애서 단말 노드를 가져올 때 height만큼의 노드를 다 가져오지 않아도 됨.<br>
이미 메모리에 있는 것들은 스킵할 수 있으니 하위 노드의 것들만 가져오면 됨.<br>

### Page Replacement
evict를 할 때는 이후에 실행되는 disk 접근을 최소화할 수 있는 방법으로 해야 함.<br>
그래서 이 정책을 page-replacement policy라고 함.<br>
자원들에 대한 접근을 사전에 알고 있다면 좋겠지만 그걸 알기 어려움.<br>
그렇다고 캐시 크기를 늘리는게 해법이 되지는 않음
belady's anomaly에 따르면 오히려 fault가 더 자주 발생함.<br>

#### FIFO and LRU
FIFO는 가장 단순한 방식.<br>
큐에서 처럼 가장 먼저 들어온 페이지를 evict하는 방식임.<br>
이 방식은 접근 빈도를 전혀 고려하지 않기 때문에 좋은 선택이 아님.<br>

LRU는 FIFO를 확장한건데, 마찬가지로 큐를 쓰지만 재접근 시 큐의 끝으로 이동시켜서 제거 우선 순위에서 가장 후순위로 밀어줌.<br>
대신 이 노드를 큐의 가장 끝으로 옮기는 작업을 자꾸 해야하니 또 비효율 발생함.<br>

외에도 2Q나 LRU-K 같은 변형이 있음.<br>

#### CLOCK
다음으로 리눅스에서도 쓰는 CLOCK 알고리즘이 있음.<br>

원형의 버퍼가 있고 각 페이지에는 access bit가 있음.<br>
접근 시 이 비트를 1로 설정함.<br>

접근 비트가 1이고 현재 접근 중이 아니라면 0으로 바꾸는데 이는 퇴출 대상이 됨.<br>

#### LFU
페이지 접근 빈도를 기준으로 evict 대상을 선택.<br>
빈도 히스토그램을 사용하고, 데이터는 3 종류의 큐 중 하나에 포함됨.<br>

1. admission: 방금 들어온, 재접근을 위해서는 probation에 추가되어야 함
2. probation: 퇴출 후보
3. protected: 장기 보관 대상

매번 퇴출 대상을 찾는게 아니라 승격 대상을 찾음.<br>
protected가 가득 차면 하나씩 probation으로 evict함.<br>